"""Configure and setup a program execution of the MorphFITS program.

There are two primary settings objects.
1. RuntimeSettings
    Settings related to runtime configurations, such as paths to data
    directories, which stages to run, which products to remake, etc.
2. ScienceSettings
    Settings related to scientific configurations, such as sigma generation
    algorithm.
"""

# Imports


import logging
import shutil
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Annotated, Union, Optional

from tqdm import tqdm
import yaml
from pydantic import BaseModel, StringConstraints

from . import DATA_ROOT
from .utils import logs, misc, science


# Constants


pre_logger = logging.getLogger("SETTINGS")
logger = logging.getLogger("SETTINGS")
"""Logger objects for this module.
"""


## Filesystem


PATH_STANDARDS_PATH = DATA_ROOT / "paths.yaml"
PATH_STANDARDS_DICT = yaml.safe_load(open(PATH_STANDARDS_PATH, mode="r"))
"""Path and dict representing the MorphFITS filesystem structuring standards.
"""


def index_paths(node: dict[str, str | dict], base: str) -> dict[str, str]:
    """Recursively read the MorphFITS filesystem standards YAML file and
    translate it into a dictionary mapping the path names to their corresponding
    paths, as string templates.

    Each value in the dictionary is a full path template, i.e. 'output_ficlo'
    has the value '[root]/[o]/{F}/{I}/{C}/{L}/{O}' and not '{O}'.

    Parameters
    ----------
    node : dict[str, str | dict]
        Dict mapping str path names to their paths (if a file) or subitems (if a
        directory).
    base : str
        Path prior to this node, as a '/'-delimited string.

    Returns
    -------
    dict[str, str]
        Dict mapping path names to their paths, as string templates.
    """
    # Start with an empty dict for this directory
    index = {}

    # Iterate over each subitem of this directory
    for key, value in node.items():
        # Skip meta keys as they are not subitems
        if key == "_name":
            continue

        # Add files to dictionary
        if isinstance(value, str):
            index[key] = base + "/" + value

        # Add subdirectories to dictionary
        else:
            index[key] = value["_name"]
            if len(base) > 0:
                index[key] = base + "/" + index[key]

            # Concatenate this directory's dictionary with the dictionary
            # generated by the subdirectory
            index = index | index_paths(node=value, base=index[key])

    # Return dictionary from path name to path for this directory
    return index


FILESYSTEM = index_paths(node=PATH_STANDARDS_DICT, base="")
"""Paths to directories and files, as structured and named by `PATH_STANDARDS`.
"""


DEFAULT_INPUT_DIRECTORY_NAME = "input"
DEFAULT_OUTPUT_DIRECTORY_NAME = "output"
DEFAULT_PRODUCT_DIRECTORY_NAME = "products"
DEFAULT_RUN_DIRECTORY_NAME = "runs"
"""Default names for each top-level root directory.
"""


## Required Files


REQUIRED_INPUT_DIRECTORIES = ["input_psfs", "input_fil"]
REQUIRED_OUTPUT_DIRECTORIES = [
    "output_merge_catalogs",
    "output_morphology_catalogs",
    "output_histograms",
    "output_ficlo",
    "product_ficlo",
]
"""Path names of required directories for MorphFITS to run on a FICLO.
"""


REQUIRED_FIC_INPUTS = ["input_segmap", "input_catalog"]
REQUIRED_FICL_INPUTS = ["input_psf", "exposure", "science", "weights"]
"""Path names of required files for a FICLO to run.
"""


REQUIRED_PRODUCT_FILES = ["stamp"]
REQUIRED_GALFIT_OUTPUT_FILES = ["model_galfit"]
REQUIRED_IMCASCADE_OUTPUT_FILES = ["model_imcascade"]
REQUIRED_PYSERSIC_OUTPUT_FILES = ["model_pysersic"]
"""Path names of required files for a FICLO to be considered successful.
"""


## FICLO


DEFAULT_CATALOG_VERSION = "dja-v7.2"
"""Default catalog version, v7.2 of the DJA catalogue.
"""


# Classes


## Models


class FICL(BaseModel):
    """Configuration model for a single FICL.

    FICL is an abbreviation for the field, image version, catalog version, and
    filter of a JWST science observation. Each FICL corresponds to a single
    observation.

    Attributes
    ----------
    field : str
        Field of observation, e.g. "abell2744clu".
    image_version : str
        Version string of JWST image processing, e.g. "grizli-v7.2".
    catalog_version : str
        Version string of JWST cataloging, e.g. "dja-v7.2".
    filter : str
        Observational filter band, e.g. "f140w".
    objects : list[int]
        Integer IDs of galaxies or cluster targets in catalog.
    pixscale : tuple[float, float]
        Pixel scale along x and y axes, in arcseconds per pixel.

    Notes
    -----
    All strings are converted to lowercase upon validation.
    """

    field: Annotated[str, StringConstraints(to_lower=True)]
    image_version: Annotated[str, StringConstraints(to_lower=True)]
    catalog_version: Annotated[str, StringConstraints(to_lower=True)]
    filter: Annotated[str, StringConstraints(to_lower=True)]
    objects: list[int]
    pixscale: tuple[float, float]

    def __str__(self) -> str:
        return "_".join(
            [self.field, self.image_version, self.catalog_version, self.filter]
        )

    def remove_objects(self, objects_to_remove: list[int]):
        """Remove objects from this FICL's configuration.

        Does nothing if an object is not in FICL's list.

        Parameters
        ----------
        objects : list[int]
            Integer IDs of objects to remove from list of objects.
        """
        for object in objects_to_remove:
            for i in range(len(self.objects)):
                if object == self.objects[i]:
                    self.objects.pop(i)
                    break


## Settings


class PathSettings(BaseModel):
    """Paths to root directories for this program run.

    Attributes
    ----------
    root : Path
        Path to root MorphFITS directory.
    input : Path
        Path to root input directory.
    output : Path
        Path to root output directory.
    product : Path
        Path to root product directory.
    run : Path
        Path to root run directory.
    """

    root: Path
    input: Path
    output: Path
    product: Path
    run: Path


class StageSettings(BaseModel):
    """Settings for MorphFITS stages, i.e. which stages are to be run in a
    program run.

    Attributes
    ----------
    unzip : bool, optional
        Unzip any zipped input files, by default True.
    product : bool, optional
        Create product files, by default True.
    morphology : bool, optional
        Run morphology fitting programs, by default True.
    catalog : bool, optional
        Create and update catalog files, by default True.
    histogram : bool, optional
        Create histogram files from catalogs, by default True.
    plot : bool, optional
        Create plots from product and output files, by default True.
    cleanup : bool, optional
        Remove failed subdirectories and record settings, by default True.
    """

    unzip: bool = True
    product: bool = True
    morphology: bool = True
    catalog: bool = True
    histogram: bool = True
    plot: bool = True
    cleanup: bool = True


class RemakeSettings(BaseModel):
    """Settings for remaking, i.e. which files to remake and overwrite.

    Attributes
    ----------
    stamps : bool, optional
        Remake stamp files, by default True.
    sigmas : bool, optional
        Remake sigma map files, by default True.
    psfs : bool, optional
        Remake PSF crop files, by default True.
    masks : bool, optional
        Remake mask files, by default True.
    morphology : bool, optional
        Rerun morphology fitting programs, by default True.
    plots : bool, optional
        Remake plots, by default True.
    others : bool, optional
        Remake any other files (e.g. feedfiles), by default True.
    """

    stamps: bool = False
    sigmas: bool = False
    psfs: bool = False
    masks: bool = False
    morphology: bool = False
    plots: bool = False
    others: bool = False


class MorphologySettings(BaseModel):
    """Settings for the morphology fitting program for this program run."""

    def _name(self) -> str:
        return ""

    def _upper_name(self) -> str:
        return ""


class GALFITSettings(MorphologySettings):
    """Settings for a GALFIT run.

    Attributes
    ----------
    binary : Path
        Path to GALFIT executable binary file.
    boost : float
        Boost in brightness applied to the estimate prior to running GALFIT,
        i.e. subtract this value from the estimate, by default 1.0.
        Included as a result of GALFIT tending to fail on accurately or
        underestimated values.
    sky : bool
        Fit background sky during morphology, by default True.
    """

    binary: Path
    boost: float = 1.0
    sky: bool = True

    def _name(self) -> str:
        return "galfit"

    def _upper_name(self) -> str:
        return "GALFIT"


class ImcascadeSettings(MorphologySettings):
    """Settings for an imcascade run."""

    def _name(self) -> str:
        return "imcascade"

    def _upper_name(self) -> str:
        return "ImCascade"


class PysersicSettings(MorphologySettings):
    """Settings for a pysersic run."""

    def _name(self) -> str:
        return "pysersic"

    def _upper_name(self) -> str:
        return "PySersic"


class RuntimeSettings(BaseModel):
    """Settings for a program run of MorphFITS.

    Attributes
    ----------
    date_time : datetime
        Date time of start of this program run.
    process_id : int, optional
        Process ID if multiple are started at the same time, by default 0.
    process_count : int, optional
        Process number if multiple are started at the same time, by default 1.
    log_level : str, optional
        Level at which to log, one of standard Python logging levels, by default
        info.
    progress_bar : bool, optional
        Display a progress bar via tqdm and suppress per-object logging, by
        default False.
    ficls : list[FICL]
        List of FICLs over which to run MorphFITS.
    roots : PathSettings
        Paths to root directories for this program run.
    stages : StageSettings | None
        Stages to run in this program run, by default None (N/A).
    remake : RemakeSettings | None
        Files to remake in this program run, by default None (N/A).
    morphology : MorphologySettings | None
        Settings for morphology fitting programs, by default None (N/A).
    """

    date_time: datetime
    process_id: int = 0
    process_count: int = 1
    log_level: str = logging._levelToName[logging.INFO]
    progress_bar: bool = False
    ficls: list[FICL]
    roots: PathSettings
    stages: Optional[StageSettings] = None
    remake: Optional[RemakeSettings] = None
    morphology: Optional[MorphologySettings] = None

    def setup_directories(self, initialized: bool = True):
        """Create required input, output, and/or product directories for this
        program run.

        Parameters
        ----------
        initialized : bool, optional
            Input directory initialized, by default True (not running initialize
            command).
        """
        pre_logger.info("Making missing directories.")

        # Create run directory
        get_path(name="run", runtime_settings=self, field=self.ficls[0].field).mkdir(
            parents=True, exist_ok=True
        )

        # If running morphology, only create output and product directories
        if initialized:
            # Iterate over each FICL
            for ficl in self.ficls:
                # Iterate over each object in FICL
                for object in tqdm(ficl.objects, unit="dir", leave=False):
                    # Make leaf FICLO directories
                    for required_directory_name in REQUIRED_OUTPUT_DIRECTORIES:
                        get_path(
                            name=required_directory_name,
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        ).mkdir(parents=True, exist_ok=True)

        # If running initialize command, only create input directories
        else:
            # Iterate over each FICL
            for ficl in self.ficls:
                # Make PSF and FIL directories, and any parents
                for required_directory_name in REQUIRED_INPUT_DIRECTORIES:
                    get_path(
                        name=required_directory_name,
                        path_settings=self.roots,
                        ficl=ficl,
                    ).mkdir(parents=True, exist_ok=True)

    def setup_loggers(self):
        """Create logging objects for this program run."""
        # Create logger object
        logs.create_logger(
            filename=get_path(
                name="run_log",
                runtime_settings=self,
                field=self.ficls[0].field,
            ),
            level=self.log_level,
        )
        global logger
        logger = logging.getLogger("SETTINGS")

    def cleanup_directories(
        self, ficl: FICL | None = None, objects: list[int] | None = None
    ):
        """Remove output and/or product directories of failed FICLOs, i.e.
        objects whose products or output files failed to generate.

        Parameters
        ----------
        ficl : FICL | None, optional
            FICL whose directories to cleanup, by default None (iterate over all
            FICLs in this run).
        objects : list[int] | None, optional
            Object IDs whose directories to cleanup, by default None (iterate
            over all objects in this FICL).
        """
        logger.info("Removing failed directories.")

        # Iterate over each FICL
        for ficl in self.ficls if ficl is None else [ficl]:
            # Iterate over each object in FICL
            for object in tqdm(
                ficl.objects if objects is None else objects, unit="dir", leave=False
            ):
                # Iterate over each expected product file
                for required_file_name in REQUIRED_PRODUCT_FILES:
                    # Remove product directory for FICLO if any product missing
                    product_path = get_path(
                        name=required_file_name,
                        path_settings=self.roots,
                        ficl=ficl,
                        object=object,
                    )
                    if not product_path.exists():
                        product_ficlo_path = get_path(
                            name="product_ficlo",
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        )
                        shutil.rmtree(product_ficlo_path, ignore_errors=True)

                # Iterate over each expected output file
                if isinstance(self.morphology, GALFITSettings):
                    required_output_files = REQUIRED_GALFIT_OUTPUT_FILES
                elif isinstance(self.morphology, ImcascadeSettings):
                    required_output_files = REQUIRED_IMCASCADE_OUTPUT_FILES
                else:
                    required_output_files = REQUIRED_PYSERSIC_OUTPUT_FILES
                for required_file_name in required_output_files:
                    # Remove output directory for FICLO if any output missing
                    output_path = get_path(
                        name=required_file_name,
                        path_settings=self.roots,
                        ficl=ficl,
                        object=object,
                    )
                    if not output_path.exists():
                        output_ficlo_path = get_path(
                            name="output_ficlo",
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        )
                        shutil.rmtree(output_ficlo_path, ignore_errors=True)

    def write(self):
        """Record runtime settings to run directory."""
        logger.info("Recording runtime settings.")

        # Initialize empty dict for writing
        settings = {}

        # Add paths as strings
        settings["roots"] = {}
        for root_name in self.roots.__dict__:
            settings["roots"][root_name] = str(self.roots.__dict__[root_name])

        # Add run details
        settings["date_time"] = self.date_time
        settings["process_id"] = self.process_id
        settings["process_count"] = self.process_count
        settings["log_level"] = self.log_level
        settings["progress_bar"] = self.progress_bar

        # Add stages as a list of stages ran
        if self.stages is not None:
            settings["stages"] = []
            for stage in self.stages.__dict__:
                if self.stages.__dict__[stage]:
                    settings["stages"].append(stage)

        # Add remake flags as a list of products remade
        if self.remake is not None:
            settings["remake"] = []
            for product in self.remake.__dict__:
                if self.remake.__dict__[product]:
                    settings["remake"].append(product)

        # Add FICLs as a list of dicts
        settings["ficls"] = []
        for ficl in self.ficls:
            settings["ficls"].append(ficl.__dict__)
            settings["ficls"][-1]["pixscale"] = {
                "x": ficl.pixscale[0],
                "y": ficl.pixscale[1],
            }

        # Append settings to file
        settings_path = get_path(
            name="run_settings", runtime_settings=self, field=self.ficls[0].field
        )
        yaml.dump(settings, open(settings_path, mode="a"), sort_keys=False)


class ScienceSettings(BaseModel):
    """Settings for scientific generation for a program run of MorphFITS.

    Parameters
    ----------
    scale : float
        Scale factor by which to multiply the initial radius (usually Kron) for
        image size, by default 20.
    psf_copy : bool
        Generate one PSF crop per filter (FICL) and copy to the directory prior
        to running morphology, rather than generating one PSF crop per object
        (FICLO), by default True.
    psf_size : int
        Size of per-filter PSF crop, in pixels, by default 80.
    morphology : MorphologySettings | None
        Settings for morphology fitting programs, by default None (N/A).
    """

    scale: float = 20
    psf_copy: bool = True
    psf_size: int = 80
    morphology: Optional[MorphologySettings] = None

    def write(self, runtime_settings: RuntimeSettings):
        """Record science settings to run directory."""
        logger.info("Recording science settings.")

        # Initialize empty dict for writing
        settings = {
            "science": {
                "scale": self.scale,
                "psf_copy": self.psf_copy,
                "psf_size": self.psf_size,
            }
        }

        # Add morphology wrapper as a str
        if self.morphology is not None:
            if isinstance(self.morphology, GALFITSettings):
                settings["science"]["galwrap"] = {
                    "binary": str(self.morphology.binary),
                }
                for (
                    morphology_setting,
                    morphology_value,
                ) in self.morphology.__dict__.items():
                    if morphology_setting == "binary":
                        continue
                    settings["science"]["galwrap"][
                        morphology_setting
                    ] = morphology_value
            elif isinstance(self.morphology, ImcascadeSettings):
                settings["science"]["imcascade"] = {}
            else:
                settings["science"]["pysersic"] = {}

        # Write settings to file
        settings_path = get_path(
            name="run_settings",
            runtime_settings=runtime_settings,
            field=runtime_settings.ficls[0].field,
        )
        yaml.dump(settings, open(settings_path, mode="w"), sort_keys=False)


# Functions


## Tertiary


def get_priority_path(
    name: str, cli_settings: dict, file_settings: dict
) -> Path | None:
    """Get the priority value for a path setting from values passed from a
    terminal call and a settings file.

    Parameters
    ----------
    name : str
        Name of path setting.
    cli_settings : dict
        Settings passed from CLI call.
    file_settings : dict
        Settings passed from YAML file.

    Returns
    -------
    Path | None
        Priority path setting, if found in either CLI call or YAML file.
    """
    # Try getting preferred setting and casting to path object
    try:
        path_str = get_priority_setting(name, cli_settings, file_settings)
        return misc.get_path_obj(path_str)

    # If setting unset or invalid, return None
    except:
        return


def get_priority_stage(
    stage: str, cli_settings: dict, file_settings: dict
) -> bool | None:
    """Get the priority value for a stage setting from values passed from a
    terminal call and a settings file.

    Parameters
    ----------
    stage : str
        Name of stage.
    cli_settings : dict
        Settings passed from CLI call.
    file_settings : dict
        Settings passed from YAML file.

    Returns
    -------
    bool | None
        Priority stage setting, if found in either CLI call or YAML file.
    """
    # Return opposite of flag from CLI call if set
    if cli_settings[f"skip_{stage}"] is not None:
        return not cli_settings[f"skip_{stage}"]

    # Return flag from YAML file if set
    elif "stages" in file_settings:
        if stage in file_settings["stages"]:
            return True
        else:
            return False

    # Return None if unset


def get_priority_remake(
    product: str, cli_settings: dict, file_settings: dict
) -> bool | None:
    """Get the priority value for a remake setting from values passed from a
    terminal call and a settings file.

    Parameters
    ----------
    product : str
        Name of file to be regenerated.
    cli_settings : dict
        Settings passed from CLI call.
    file_settings : dict
        Settings passed from YAML file.

    Returns
    -------
    bool | None
        Priority remake setting, if found in either CLI call or YAML file.
    """
    # Return opposite of flag from CLI call if set
    if cli_settings[f"remake_{product}"] is not None:
        return cli_settings[f"remake_{product}"]

    # Return flag from YAML file if set
    elif ("remake" in file_settings) and (product in file_settings["remake"]):
        return True

    # Return None if unset


def get_priority_science_setting(
    name: str, cli_settings: dict, file_settings: dict
) -> float | None:
    """Get a priority value for a science setting from values passed from a
    terminal call and a settings file.

    Parameters
    ----------
    name : str
        Name of setting.
    cli_settings : dict
        Settings passed from CLI call.
    file_settings : dict
        Settings read from YAML file.

    Returns
    -------
    float | None
        Resolved prioritized science setting, if found.
    """
    # Return setting from CLI call if set
    if cli_settings[name] is not None:
        return cli_settings[name]

    # Return setting from YAML file if set
    elif ("science" in file_settings) and (name in file_settings["science"]):
        return file_settings["science"][name]

    # Return None if unset


def validate_batch_settings(
    process_count: int | None,
    process_id: int | None,
    first_object: int | None,
    last_object: int | None,
):
    """Validate batch mode settings for a MorphFITS program run.

    Parameters
    ----------
    process_count : int | None
        Number of processes in batch, must be greater than 0.
    process_id : int | None
        ID of process in batch, must be greater than 0 and less than total
        number of processes.
    first_object : int | None
        ID of first object in batch range, must be greater than 0 and less than
        last (possible) object.
    last_object : int | None
        ID of last object in batch range, must be greater than first (possible)
        object and less than last possible object.
    """
    # Terminate if invalid number of processes
    if process_count is not None:
        assert process_count > 0, f"Invalid # processes {process_count}."

    # Terminate if invalid process ID
    if process_id is not None:
        assert process_id >= 0, f"Invalid process ID {process_id}."
        if process_count is not None:
            assert (
                process_id < process_count
            ), f"Invalid process ID {process_id} for # processes {process_count}."

    # Terminate if invalid first object
    if first_object is not None:
        assert first_object > 0, f"Invalid first object ID {first_object}."

    # Terminate if invalid last object
    if last_object is not None:
        assert last_object > 0, f"Invalid last object ID {last_object}."

    # Terminate if invalid object range
    if (first_object is not None) and (last_object is not None):
        assert (
            first_object <= last_object
        ), f"Invalid object range {first_object} to {last_object}."


def missing_input(
    input_root: Path,
    field: str,
    image_version: str,
    catalog_version: str,
    filter: str | None = None,
) -> Path | None:
    """Evaluate whether a FICL (corresponding to an observation) or FIC
    (corresponding to a catalog) is missing an input file.

    Parameters
    ----------
    input_root : Path
        Path to root input directory.
    field : str
        Name of field.
    image_version : str
        Image processing version.
    catalog_version : str
        Cataloging version.
    filter : str | None, optional
        Name of filter, by default None (FIC).

    Returns
    -------
    Path | None
        First found missing input file, if any.
    """
    # Get list of path names of required input files
    required_inputs = REQUIRED_FIC_INPUTS if filter is None else REQUIRED_FICL_INPUTS

    # Iterate over each required input file
    for required_input in required_inputs:
        # Get path to required input file
        input_path = get_path(
            name=required_input,
            input_root=input_root,
            field=field,
            image_version=image_version,
            catalog_version=catalog_version,
            filter=filter,
        )

        # Return missing input file path if FIC/FICL missing any input file
        if not input_path.exists():
            return input_path

    # Return None if not missing any input files


def get_objects(
    input_root: Path,
    field: str,
    image_version: str,
    catalog_version: str,
    objects: list[int] | None,
    process_count: int | None,
    process_id: int | None,
    first_object: int | None,
    last_object: int | None,
) -> list[int]:
    """Get a list of objects for a FICL for this program run (whether or not in
    batch mode), as a list of integer IDs corresponding to their IDs in the
    photometric catalog corresponding to the FICL.

    Parameters
    ----------
    input_root : Path
        Path to root input directory.
    field : str
        Name of field.
    image_version : str
        Image processing version.
    catalog_version : str
        Cataloging version.
    objects : list[int] | None
        List of objects from user, by default None (not passed).
    process_count : int | None
        Number of processes in batch, by default None (not passed).
    process_id : int | None
        ID of process in batch, by default None (not passed).
    first_object : int | None
        ID of first object in batch, by default None (not passed).
    last_object : int | None
        ID of last object in batch, by default None (not passed).

    Returns
    -------
    list[int]
        List of object IDs corresponding to the 'id' key in the FICL's
        photometric catalog.
    """
    # Base list of objects is all possible object IDs, if in batch mode
    if (
        (objects is None)
        or (process_count is not None)
        or (first_object is not None)
        or (last_object is not None)
    ):
        input_catalog_path = get_path(
            name="input_catalog",
            input_root=input_root,
            field=field,
            image_version=image_version,
            catalog_version=catalog_version,
        )
        new_object_range = science.get_all_objects(input_catalog_path)
        first_possible_object = new_object_range[0]
        last_possible_object = new_object_range[-1]

    # Base list of objects is the sorted list of object IDs, otherwise
    else:
        new_object_range = sorted(objects)

    # Remove all object IDs before first object setting
    if first_object is not None:
        while new_object_range[0] < first_object:
            new_object_range.pop(0)

    # Remove all object IDs after last object setting
    if last_object is not None:
        while new_object_range[-1] > last_object:
            new_object_range.pop(-1)

    # Remove all object IDs not in batch process
    if process_count is not None:
        ## Get sub-range indices and values from batch settings
        start_index, stop_index = misc.get_unique_batch_limits(
            process_id=process_id,
            n_process=process_count,
            n_items=len(new_object_range),
        )
        new_object_range = new_object_range[start_index:stop_index]

        ## Remove objects out of range
        while (len(new_object_range) > 0) and (
            new_object_range[0] < first_possible_object
        ):
            new_object_range.pop(0)
        while (len(new_object_range) > 0) and (
            new_object_range[-1] > last_possible_object
        ):
            new_object_range.pop(-1)

    # Return final list of objects for this catalog (FIC) and runtime
    return new_object_range


def clean_filter(
    input_root: Path, field: str, image_version: str, catalog_version: str, filter: str
) -> str | None:
    """Get the filter name corresponding to existing input files.

    For an existing science file '...f200w-clear...fits', the cleaned filter
    refers to 'f200w-clear', and uncleaned filters refer to those passed by
    users indicating this filter without being identical strings, e.g. 'f200w'.

    Parameters
    ----------
    input_root : Path
        Path to root input directory.
    field : str
        Name of field.
    image_version : str
        Image processing version.
    catalog_version : str
        Cataloging version.
    filter : str
        Uncleaned filter.

    Returns
    -------
    str | None
        Cleaned filter, if found.
    """
    # Get path to input science frame
    science_path = get_path(
        name="science",
        input_root=input_root,
        field=field,
        image_version=image_version,
        filter=filter,
    )

    # Filter is valid if science frame exists
    if science_path.exists():
        return filter

    # Filter is invalid otherwise, try other known filter formats
    all_possible_filters = [
        f"{filter}-clear",
        f"clear-{filter}",
        f"{filter}-clearp",
        f"clearp-{filter}",
        filter.replace("clear", "").replace("-", ""),
        filter.replace("clearp", "").replace("-", ""),
    ]

    # Iterate over each known filter format
    for possible_filter in all_possible_filters:
        # Get path to input science frame
        possible_science_path = get_path(
            name="science",
            input_root=input_root,
            field=field,
            image_version=image_version,
            filter=possible_filter,
        )

        # Return new filter name if matching file found
        if possible_science_path.exists():
            pre_logger.debug(f"Filter {possible_filter}: Changing from {filter}.")
            return possible_filter


## Secondary


def get_priority_setting(
    name: str, cli_settings: dict, file_settings: dict
) -> bool | int | Path | list[str] | list[int] | None:
    """Get a setting's value from CLI call or YAML file, in preference of the
    CLI setting value, and None if not found.

    Parameters
    ----------
    name : str
        Name of setting.
    cli_settings : dict
        Settings passed from CLI call.
    file_settings : dict
        Settings read from YAML file.

    Returns
    -------
    bool | int | Path | list[str] | list[int] | None
        Resolved prioritized setting, if found.
    """
    # Return setting from CLI call if set
    if cli_settings[name] is not None:
        return cli_settings[name]

    # Return setting from YAML file if set
    elif name in file_settings:
        return file_settings[name]

    # Return None if unset


def get_path_settings(cli_settings: dict, file_settings: dict) -> PathSettings:
    """Get path settings for this program run from the CLI call and YAML file,
    if passed.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    PathSettings
        Paths to root MorphFITS directories.

    Raises
    ------
    ValueError
        Path to input root AND MorphFITS root not passed.
    FileNotFoundError
        Input root directory does not exist.
    """
    # Set initialized flag from parameter from main command
    initialized = cli_settings["initialized"]

    # Get either path objects or None
    settings_pack = [cli_settings, file_settings]
    root = get_priority_path("morphfits_root", *settings_pack)
    input = get_priority_path("input_root", *settings_pack)
    output = get_priority_path("output_root", *settings_pack)
    product = get_priority_path("product_root", *settings_pack)
    run = get_priority_path("run_root", *settings_pack)

    # Input root must be set
    if input is None:
        # Terminate if MorphFITS root is also unset
        if root is None:
            raise ValueError("Terminating - input root unset.")

        # Otherwise assume input root exists and is under root
        else:
            input = root / DEFAULT_INPUT_DIRECTORY_NAME
            assert (
                input.exists() or not initialized
            ), f"Terminating - input root {input} not found."

    # Input root should exist
    elif not input.exists():
        # Terminate if input root set but does not exist
        if initialized:
            raise FileNotFoundError(f"Terminating - input root {input} not found.")

        # Create input root if main command is initialize
        else:
            input.mkdir(parents=True)

    # Set root directory, if not found, as parent of input root
    if root is None:
        root = input.parent

    # Set product, output, and run directories from root directory
    if output is None:
        output = root / DEFAULT_OUTPUT_DIRECTORY_NAME
    if product is None:
        product = root / DEFAULT_PRODUCT_DIRECTORY_NAME
    if run is None:
        run = root / DEFAULT_RUN_DIRECTORY_NAME

    # Return created and validated object
    return PathSettings(root=root, input=input, output=output, product=product, run=run)


def get_ficls(
    cli_settings: dict,
    file_settings: dict,
    input_root: Path,
    process_count: int | None,
    process_id: int | None,
    first_object: int | None,
    last_object: int | None,
) -> list[FICL]:
    """Get a list of FICLs (corresponding to observations) over which to run
    MorphFITS.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.
    input_root : Path
        Path to root input directory.
    process_count : int | None
        Number of processes in batch.
    process_id : int | None
        ID of process in batch.
    first_object : int | None
        ID of first object in range.
    last_object : int | None
        ID of last object in range.

    Returns
    -------
    list[FICL]
        List of FICLs over which to run MorphFITS.

    Raises
    ------
    KeyError
        No valid FICLs found for these settings.
    """
    # Get preferred FICLO settings
    settings_pack = [cli_settings, file_settings]
    fields = get_priority_setting("fields", *settings_pack)
    imvers = get_priority_setting("image_versions", *settings_pack)
    catvers = get_priority_setting("catalog_versions", *settings_pack)
    filters = get_priority_setting("filters", *settings_pack)
    objects = get_priority_setting("objects", *settings_pack)

    # Display settings to be searched for from input
    log_str = "Searching for missing settings -"
    if fields is None:
        log_str += " fields,"
    if imvers is None:
        log_str += " image versions,"
    if catvers is None:
        log_str += " catalog versions,"
    if filters is None:
        log_str += " filters,"
    if objects is None:
        log_str += " objects,"
    if log_str[-1] == ",":
        pre_logger.debug(log_str[:-1] + ".")

    # Initialize list of FICLs
    ficls = []

    # Get list of paths to field-level directories (input root subdirectories)
    if fields is None:
        f_paths = misc.get_subdirectories(input_root)

        ## Remove PSFs directory, as it is also an input root subdirectory
        for f_path in f_paths:
            if f_path.name == "psfs":
                f_paths.remove(f_path)
                break
    else:
        f_paths = [input_root / field for field in fields]

    # Iterate over each field directory
    for f_path in f_paths:
        # Get list of paths to image-version-level directories
        if imvers is None:
            fi_paths = misc.get_subdirectories(f_path)
        else:
            fi_paths = [f_path / imver for imver in imvers]

        # Iterate over each image version directory
        for fi_path in fi_paths:
            # Set catalog version to default if unset
            if catvers is None:
                catvers = [DEFAULT_CATALOG_VERSION]

            # Iterate over each catalog version
            for catver in catvers:
                # Skip FIC if missing any input
                missing_file = missing_input(
                    input_root=input_root,
                    field=f_path.name,
                    image_version=fi_path.name,
                    catalog_version=catver,
                )
                if missing_file:
                    pre_logger.warning(
                        f"FIC {'_'.join([f_path.name,fi_path.name,catver])}: "
                        + f"Skipping - missing input file '{missing_file.name}'."
                    )
                    continue

                # Get object ID range unique to catalog for FIC
                objects = get_objects(
                    input_root=input_root,
                    field=f_path.name,
                    image_version=fi_path.name,
                    catalog_version=catver,
                    objects=objects,
                    process_count=process_count,
                    process_id=process_id,
                    first_object=first_object,
                    last_object=last_object,
                )

                # Get list of paths to filter-level directories
                if filters is None:
                    ficl_paths = misc.get_subdirectories(fi_path)
                else:
                    ficl_paths = [fi_path / filter for filter in filters]

                # Iterate over each filter directory
                for ficl_path in ficl_paths:
                    # Get cleaned filter name
                    cleaned_filter = clean_filter(
                        input_root=input_root,
                        field=f_path.name,
                        image_version=fi_path.name,
                        catalog_version=catver,
                        filter=ficl_path.name,
                    )

                    # Skip filter if cleaned name not found
                    if cleaned_filter is None:
                        continue

                    # Skip FICL if missing any input
                    missing_file = missing_input(
                        input_root=input_root,
                        field=f_path.name,
                        image_version=fi_path.name,
                        catalog_version=catver,
                        filter=cleaned_filter,
                    )
                    if missing_file:
                        pre_logger.warning(
                            f"FICL {'_'.join([f_path.name,fi_path.name,catver,cleaned_filter])}: "
                            + f"Skipping - missing input file '{missing_file.name}'."
                        )
                        continue

                    # Get pixscale from science frame
                    try:
                        science_path = get_path(
                            name="science",
                            input_root=input_root,
                            field=f_path.name,
                            image_version=fi_path.name,
                            catalog_version=catver,
                            filter=cleaned_filter,
                        )
                        pixscale = science.get_pixscale(science_path)
                    except Exception as e:
                        logger.error(e)
                        pixscale = [0.04, 0.04]

                    # Create FICL object and add to list
                    ficl = FICL(
                        field=f_path.name,
                        image_version=fi_path.name,
                        catalog_version=catver,
                        filter=cleaned_filter,
                        objects=objects,
                        pixscale=pixscale,
                    )
                    pre_logger.info(f"FICL {ficl}: Adding.")
                    ficls.append(ficl)

    # Terminate if no FICLs set
    if len(ficls) == 0:
        pre_logger.error("Terminating, no FICLs with valid data found.")
        raise KeyError("Terminating, no FICLs with valid data found.")

    # Return list of FICLs
    return ficls


def get_ficls_to_initialize(cli_settings: dict, file_settings: dict) -> list[FICL]:
    """Get a list of FICLs to initialize, i.e. download data for from DJA.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    list[FICL]
        List of FICLs to initialize.

    Raises
    ------
    KeyError
        No valid FICLs found to initialize.
    """
    # Get preferred FIL settings
    settings_pack = [cli_settings, file_settings]
    fields = get_priority_setting("fields", *settings_pack)
    imvers = get_priority_setting("image_versions", *settings_pack)
    filters = get_priority_setting("filters", *settings_pack)

    # NOTE Terminates if any of FIL unset, in future can implement discovery
    if (fields is None) or (imvers is None) or (filters is None):
        raise KeyError("FICLs not set for initialization.")

    # Iterate over each FIL permutation
    # NOTE Uses default catalog version
    ficls = []
    for field in fields:
        for imver in imvers:
            for filter in filters:
                # Create FICL object and add to list
                ficl = FICL(
                    field=field,
                    image_version=imver,
                    catalog_version=DEFAULT_CATALOG_VERSION,
                    filter=filter,
                    objects=[-1],
                    pixscale=[-1, -1],
                )
                pre_logger.info(f"FICL {ficl}: Adding.")
                ficls.append(ficl)

    # Return list of FICLs
    return ficls


def get_stage_settings(cli_settings: dict, file_settings: dict) -> StageSettings | None:
    """Get the stages to run for this MorphFITS run.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    StageSettings | None
        Stages to run, if not running the initialize command.
    """
    # Get skip stage flags from CLI call or YAML file
    settings_pack = [cli_settings, file_settings]
    unzip = get_priority_stage("unzip", *settings_pack)
    product = get_priority_stage("product", *settings_pack)
    morphology = get_priority_stage("morphology", *settings_pack)
    catalog = get_priority_stage("catalog", *settings_pack)
    histogram = get_priority_stage("histogram", *settings_pack)
    plot = get_priority_stage("plot", *settings_pack)
    cleanup = get_priority_stage("cleanup", *settings_pack)

    # Create object dict from settings that have been set
    # Set attributes which may be None at this point, if they are set
    # Otherwise they will be set to default as per the class definition
    stage_dict = {}
    if unzip is not None:
        stage_dict["unzip"] = unzip
    if product is not None:
        stage_dict["product"] = product
    if morphology is not None:
        stage_dict["morphology"] = morphology
    if catalog is not None:
        stage_dict["catalog"] = catalog
    if histogram is not None:
        stage_dict["histogram"] = histogram
    if plot is not None:
        stage_dict["plot"] = plot
    if cleanup is not None:
        stage_dict["cleanup"] = cleanup

    # Create and return class instance from settings
    return StageSettings(**stage_dict)


def get_remake_settings(
    cli_settings: dict, file_settings: dict
) -> RemakeSettings | None:
    """Get the output and product files to remake for this program run.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    RemakeSettings | None
        Output and product files to remake in this program run.
    """
    # Return None if main command is initialize
    if not cli_settings["initialized"]:
        return

    # Get remake product flags from CLI call or YAML file
    settings_pack = [cli_settings, file_settings]
    remake_all = get_priority_remake("all", *settings_pack)
    stamps = get_priority_remake("stamps", *settings_pack)
    sigmas = get_priority_remake("sigmas", *settings_pack)
    psfs = get_priority_remake("psfs", *settings_pack)
    masks = get_priority_remake("masks", *settings_pack)
    morphology = get_priority_remake("morphology", *settings_pack)
    plots = get_priority_remake("plots", *settings_pack)
    others = get_priority_remake("others", *settings_pack)

    # Create object dict from settings that have been set
    # Set attributes which may be None at this point, if they are set
    # Otherwise they will be set to default as per the class definition
    remake_dict = {}
    if stamps is not None:
        remake_dict["stamps"] = stamps
    if sigmas is not None:
        remake_dict["sigmas"] = sigmas
    if psfs is not None:
        remake_dict["psfs"] = psfs
    if masks is not None:
        remake_dict["masks"] = masks
    if morphology is not None:
        remake_dict["morphology"] = morphology
    if plots is not None:
        remake_dict["plots"] = plots
    if others is not None:
        remake_dict["others"] = others
    if (remake_all is not None) and (remake_all):
        remake_dict["stamps"] = True
        remake_dict["sigmas"] = True
        remake_dict["psfs"] = True
        remake_dict["masks"] = True
        remake_dict["morphology"] = True
        remake_dict["plots"] = True
        remake_dict["others"] = True

    # Create and return class instance from settings
    return RemakeSettings(**remake_dict)


def get_morphology_settings(
    cli_settings: dict, file_settings: dict
) -> GALFITSettings | ImcascadeSettings | PysersicSettings | None:
    """Get the morphology settings for this program run.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    GALFITSettings | ImcascadeSettings | PysersicSettings | None
        Morphology settings for this program run.

    Raises
    ------
    KeyError
        GALFIT binary executable not passed.
    FileNotFoundError
        GALFIT binary executable not found.
    NotImplementedError
        Morphology fitting program not yet implemented.
    """
    # Return None if main command is initialize
    if not cli_settings["initialized"]:
        return

    # Return matching morphology settings instance
    match cli_settings["morphology"]:
        case "galfit":
            # Get GALFIT binary path setting from CLI or YAML
            galfit_path = get_priority_path("galfit_path", cli_settings, file_settings)

            # Terminate if not found, return setting object otherwise
            if galfit_path is None:
                raise KeyError("Terminating - GALFIT binary not provided.")
            elif not galfit_path.exists():
                raise FileNotFoundError("Terminating - GALFIT binary not found.")

            # Get brightness boost setting from CLI or YAML
            boost = get_priority_science_setting("boost", cli_settings, file_settings)
            sky = get_priority_science_setting("sky", cli_settings, file_settings)

            # Set dict from found settings
            galfit_dict = {"binary": galfit_path}
            if boost is not None:
                try:
                    galfit_dict["boost"] = float(boost)
                except:
                    pass
            if sky is not None:
                galfit_dict["sky"] = sky

            # Return GALFIT settings object
            return GALFITSettings(**galfit_dict)

        case "imcascade":
            raise NotImplementedError("Terminating - not yet implemented.")
        case "pysersic":
            raise NotImplementedError("Terminating - not yet implemented.")
        case _:
            raise NotImplementedError("Terminating - unknown morphology fitter.")


## Primary


def get_path(
    name: str,
    runtime_settings: RuntimeSettings | None = None,
    path_settings: PathSettings | None = None,
    ficl: FICL | None = None,
    morphfits_root: Path | None = None,
    input_root: Path | None = None,
    output_root: Path | None = None,
    product_root: Path | None = None,
    run_root: Path | None = None,
    field: str | None = None,
    image_version: str | None = None,
    catalog_version: str | None = None,
    filter: str | None = None,
    object: int | None = None,
    date_time: datetime | None = None,
    process_id: int | None = None,
    resolve: bool = True,
) -> Path:
    """Get the path to a MorphFITS file or directory.

    Resolution order:
    1. parameters
        a. prefer directly passed
        b. prefer objects (runtime settings, path settings, ficl)
    2. path templates ([root], [input], ...)
    3. ficlo templates ({F}, {I}, ...)
    4. drc/drz

    Parameters
    ----------
    name : str
        Name of path to get.
    runtime_settings : RuntimeSettings | None, optional
        Settings for the runtime of MorphFITS, by default None.
    path_settings : PathSettings | None, optional
        Paths to the root directories of MorphFITS, by default None.
    ficl : FICL | None, optional
        FICL object for current iteration in run, by default None.
    morphfits_root : Path | None, optional
        Path to root of MorphFITS filesystem, by default None.
    input_root : Path | None, optional
        Path to root input directory, by default None.
    output_root : Path | None, optional
        Path to root output directory, by default None.
    product_root : Path | None, optional
        Path to root products directory, by default None.
    run_root : Path | None, optional
        Path to root runs directory, by default None.
    field : str | None, optional
        Field of observation, by default None.
    image_version : str | None, optional
        Image version of science frame, by default None.
    catalog_version : str | None, optional
        Catalog version of science frame, by default None.
    filter : str | None, optional
        Filter used in observation, by default None.
    object : int | None, optional
        Target galaxy or cluster ID in catalog, by default None.
    date_time : datetime | None, optional
        Datetime at start of program run, by default None.
    process_id : int | None, optional
        Integer ID of process in batch, by default None.
    resolve : bool, optional
        Resolve path object, by default True.

    Returns
    -------
    Path
        Path to file or directory.

    Raises
    ------
    FileNotFoundError
        Passed path name unrecognized.

    See Also
    --------
    data/paths.yaml
        Data standards dictionary detailing MorphFITS paths.
    """
    # Raise error if path name unknown
    if name not in FILESYSTEM:
        raise FileNotFoundError(f"path name {name} unknown")

    # Resolve parameters
    # Prefer directly passed parameters to those from settings objects
    if ficl is not None:
        if field is None:
            field = ficl.field
        if image_version is None:
            image_version = ficl.image_version
        if catalog_version is None:
            catalog_version = ficl.catalog_version
        if filter is None:
            filter = ficl.filter
    if runtime_settings is not None:
        if morphfits_root is None:
            morphfits_root = runtime_settings.roots.root
        if input_root is None:
            input_root = runtime_settings.roots.input
        if output_root is None:
            output_root = runtime_settings.roots.output
        if product_root is None:
            product_root = runtime_settings.roots.product
        if run_root is None:
            run_root = runtime_settings.roots.run
        if date_time is None:
            date_time = runtime_settings.date_time
        if process_id is None:
            process_id = runtime_settings.process_id
    if path_settings is not None:
        if morphfits_root is None:
            morphfits_root = path_settings.root
        if input_root is None:
            input_root = path_settings.input
        if output_root is None:
            output_root = path_settings.output
        if product_root is None:
            product_root = path_settings.product
        if run_root is None:
            run_root = path_settings.run

    # Get path as str template from dict
    path = FILESYSTEM[name]

    # DEPRECATED Finds names from STSci PSFs
    # Input PSFs - STSci names with uppercase filter names
    # if name == "input_psf":
    #     # Get main filter from pairs like 'f140w-clear'
    #     if "-" in filter:
    #         filter_1, filter_2 = filter.split("-")
    #         filter = filter_1 if "clear" in filter_2 else filter_2

    #     # Replace filter template with uppercase main filter name
    #     path = path.replace("{L}", filter.upper())

    # Replace template in path str with passed value
    if morphfits_root is not None:
        path = path.replace("[root]", str(morphfits_root))
    if input_root is not None:
        path = path.replace("[i]", input_root.name)
        path = path.replace("[root]", str(input_root.parent))
    if output_root is not None:
        path = path.replace("[o]", output_root.name)
        path = path.replace("[root]", str(output_root.parent))
    if product_root is not None:
        path = path.replace("[p]", product_root.name)
        path = path.replace("[root]", str(product_root.parent))
    if run_root is not None:
        path = path.replace("[r]", run_root.name)
        path = path.replace("[root]", str(run_root.parent))
    if field is not None:
        path = path.replace("{F}", field)
    if image_version is not None:
        path = path.replace("{I}", image_version)
    if catalog_version is not None:
        path = path.replace("{C}", catalog_version)
    if filter is not None:
        path = path.replace("{L}", filter)
    if object is not None:
        path = path.replace("{O}", str(object))
    if date_time is not None:
        path = path.replace("{D}", misc.get_str_from_datetime(date_time))
    if process_id is not None:
        path = path.replace("{N}", misc.get_str_from_process_id(process_id))

    # Input PSFs - two known pixel scales of '20mas' or '40mas'
    if "{P}" in path:
        # Get paths to all known pixel scales
        path_20mas = misc.get_path_obj(path.replace("{P}", "20mas"))
        path_40mas = misc.get_path_obj(path.replace("{P}", "40mas"))

        # Return option that exists
        if path_20mas.exists():
            return path_20mas
        else:
            return path_40mas

    # Science, exposure, weights images - can contain either 'drc' or 'drz'
    if "{z}" in path:
        # Get paths to both 'drc' and 'drz'
        path_drc = misc.get_path_obj(path_like=path.replace("{z}", "c"))
        path_drz = misc.get_path_obj(path_like=path.replace("{z}", "z"))

        # Return option that exists
        if path_drz.exists():
            return path_drz
        else:
            return path_drc

    # Return resolved path object
    return misc.get_path_obj(path_like=path, resolve=resolve)


def get_runtime_settings(cli_settings: dict, file_settings: dict) -> RuntimeSettings:
    """Get the runtime settings for this program run.

    Order of resolution:
    1. paths
    2. primitive
        a. date time
        b. progress bar
        c. log level
        d. process count
        e. process ID
    3. list of FICLs
    4. stages to run
    5. files to remake
    6. morphology settings

    Creates all input, output, and product directories for this program run.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    RuntimeSettings
        Runtime settings for this program run.
    """
    # Get initialized flag from parameter passed from main command
    initialized = cli_settings["initialized"]

    # Get settings list to unpack for function calls
    settings_pack = [cli_settings, file_settings]

    # Get root paths
    roots = get_path_settings(*settings_pack)

    # Get primitive type runtime setting attributes
    date_time = datetime.now()
    progress_bar = get_priority_setting("progress_bar", *settings_pack)
    log_level = get_priority_setting("log_level", *settings_pack)
    process_id = get_priority_setting("batch_process_id", *settings_pack)
    process_count = get_priority_setting("batch_n_process", *settings_pack)
    first_object = get_priority_setting("first_object", *settings_pack)
    last_object = get_priority_setting("last_object", *settings_pack)

    # Validate batch mode settings
    validate_batch_settings(process_count, process_id, first_object, last_object)

    # Get list of FICLs
    if initialized:
        ficls = get_ficls(
            cli_settings=cli_settings,
            file_settings=file_settings,
            input_root=roots.input,
            process_count=process_count,
            process_id=process_id,
            first_object=first_object,
            last_object=last_object,
        )
    else:
        ficls = get_ficls_to_initialize(*settings_pack)

    # Get list of stages to run
    stages = get_stage_settings(*settings_pack)

    # Get list of products to remake
    remake = get_remake_settings(*settings_pack)

    # Get settings for morphology fitter
    morphology = get_morphology_settings(*settings_pack)

    # Create object dict from settings that have been set
    ## Set attributes which have definitely been set by this point
    runtime_dict = {
        "roots": roots,
        "date_time": date_time,
        "ficls": ficls,
    }

    ## Set attributes which may be None at this point, if they are set
    ## Otherwise they will be set to default as per the class definition
    if process_id is not None:
        runtime_dict["process_id"] = process_id
    if process_count is not None:
        runtime_dict["process_count"] = process_count
    if progress_bar is not None:
        runtime_dict["progress_bar"] = progress_bar
    if log_level is not None:
        runtime_dict["log_level"] = log_level
    if stages is not None:
        runtime_dict["stages"] = stages
    if remake is not None:
        runtime_dict["remake"] = remake
    if morphology is not None:
        runtime_dict["morphology"] = morphology

    # Create class instance from settings
    runtime_settings = RuntimeSettings(**runtime_dict)

    # Create directories from path settings and FICLs
    runtime_settings.setup_directories(initialized)

    # Return runtime settings object
    return runtime_settings


def get_science_settings(cli_settings: dict, file_settings: dict) -> ScienceSettings:
    """Get the science settings for this program run.

    Parameters
    ----------
    cli_settings : dict
        Settings from CLI call.
    file_settings : dict
        Settings from YAML file.

    Returns
    -------
    ScienceSettings
        Science settings for this program run.
    """
    # Get settings list to unpack for function calls
    settings_pack = [cli_settings, file_settings]

    # Get primitive settings
    scale = get_priority_science_setting("scale", *settings_pack)
    psf_copy = get_priority_science_setting("psf_copy", *settings_pack)
    psf_size = get_priority_science_setting("psf_size", *settings_pack)

    # Get settings for morphology fitter
    morphology = get_morphology_settings(*settings_pack)

    # Create object dict from settings that have been set
    science_dict = {}

    ## Set attributes which may be None at this point, if they are set
    ## Otherwise they will be set to default as per the class definition
    if scale is not None:
        science_dict["scale"] = scale
    if psf_copy is not None:
        science_dict["psf_copy"] = psf_copy
    if psf_size is not None:
        science_dict["psf_size"] = psf_size
    if morphology is not None:
        science_dict["morphology"] = morphology

    # Create class instance from settings
    science_settings = ScienceSettings(**science_dict)

    # Return science settings object
    return science_settings


def get_settings(
    settings_path: Path | None = None,
    morphfits_root: Path | None = None,
    input_root: Path | None = None,
    output_root: Path | None = None,
    product_root: Path | None = None,
    run_root: Path | None = None,
    batch_n_process: int | None = None,
    batch_process_id: int | None = None,
    fields: list[str] | None = None,
    image_versions: list[str] | None = None,
    catalog_versions: list[str] | None = None,
    filters: list[str] | None = None,
    objects: list[int] | None = None,
    first_object: int | None = None,
    last_object: int | None = None,
    progress_bar: bool | None = None,
    log_level: str | None = None,
    skip_unzip: bool | None = None,
    skip_product: bool | None = None,
    skip_morphology: bool | None = None,
    skip_catalog: bool | None = None,
    skip_histogram: bool | None = None,
    skip_plot: bool | None = None,
    skip_cleanup: bool | None = None,
    remake_all: bool | None = None,
    remake_stamps: bool | None = None,
    remake_sigmas: bool | None = None,
    remake_psfs: bool | None = None,
    remake_masks: bool | None = None,
    remake_morphology: bool | None = None,
    remake_plots: bool | None = None,
    remake_others: bool | None = None,
    morphology: str | None = None,
    galfit_path: Path | None = None,
    scale: float | None = None,
    psf_copy: bool | None = None,
    psf_size: int | None = None,
    boost: float | None = None,
    sky: bool | None = None,
    initialized: bool | None = None,
) -> tuple[RuntimeSettings, ScienceSettings]:
    """Get the runtime and science settings for this program run.

    Reads settings passed from CLI call, then from YAML file, and prefers those
    from the former. Creates temporary log file for pre-run-directory logging.
    Creates settings objects.

    Parameters
    ----------
    settings_path : Path | None, optional
        Path to config YAML file, by default None.
    morphfits_root : Path | None, optional
        Path to root MorphFITS directory, by default None.
    input_root : Path | None, optional
        Path to root input directory, by default None.
    output_root : Path | None, optional
        Path to root output directory, by default None.
    product_root : Path | None, optional
        Path to root product directory, by default None.
    run_root : Path | None, optional
        Path to root run directory, by default None.
    batch_n_process : int | None, optional
        Number of processes in batch, by default None.
    batch_process_id : int | None, optional
        ID of process in batch, by default None.
    fields : list[str] | None, optional
        List of field names, by default None.
    image_versions : list[str] | None, optional
        List of image processing versions, by default None.
    catalog_versions : list[str] | None, optional
        List of cataloging versions, by default None.
    filters : list[str] | None, optional
        List of filters, by default None.
    objects : list[int] | None, optional
        List of object IDs, by default None.
    first_object : int | None, optional
        First object ID in range, by default None.
    last_object : int | None, optional
        Last object ID in range, by default None.
    progress_bar : bool | None, optional
        Show progress bar and suppress per-object logging, by default None.
    log_level : str | None, optional
        Level at which to log, by default None.
    skip_unzip : bool | None, optional
        Skip unzipping stage, by default None.
    skip_product : bool | None, optional
        Skip product generation stage, by default None.
    skip_morphology : bool | None, optional
        Skip morphology fitting stage, by default None.
    skip_catalog : bool | None, optional
        Skip cataloging stage, by default None.
    skip_histogram : bool | None, optional
        Skip histogram generation stage, by default None.
    skip_plot : bool | None, optional
        Skip plotting stage, by default None.
    skip_cleanup : bool | None, optional
        Skip cleanup stage, by default None.
    remake_all : bool | None, optional
        Remake all files, by default None.
    remake_stamps : bool | None, optional
        Remake stamps, by default None.
    remake_sigmas : bool | None, optional
        Remake sigma maps, by default None.
    remake_psfs : bool | None, optional
        Remake PSF crops, by default None.
    remake_masks : bool | None, optional
        Remake masks, by default None.
    remake_morphology : bool | None, optional
        Rerun morphology fitting, by default None.
    remake_plots : bool | None, optional
        Remake plots, by default None.
    remake_others : bool | None, optional
        Remake any other files, by default None.
    morphology : str | None, optional
        Morphology fitting program name, by default None.
    galfit_path : Path | None, optional
        Path to GALFIT binary executable, by default None.
    scale : float | None, optional
        Scale factor by which to multiply a stamp's Kron radius for its image
        size, by default None.
    psf_copy : bool | None, optional
        Make one PSF crop per filter (FICL) rather than per object (FICLO) and
        link to FICLO directory prior to running morphology, by default None.
    psf_size : int | None, optional
        Size of per-filter PSF crop, in pixels, by default None.
    boost : float | None, optional
        Brightness boost to initial estimate, by default None.
    sky : bool | None, optional
        Fit background sky during morphology, by default None.
    initialized : bool | None, optional
        All input files acquired, organized, and unzipped, by default None.

    Returns
    -------
    tuple[RuntimeSettings, ScienceSettings]
        Runtime and science settings for this program run.
    """
    # Get CLI settings as dict from passed parameters
    cli_settings = locals()

    # Get file settings as dict from YAML file
    if settings_path is None:
        file_settings = {}
    else:
        file_settings = yaml.safe_load(open(settings_path, mode="r"))

    # Get settings list to unpack for function calls
    settings_pack = [cli_settings, file_settings]

    # Create a temporary logger
    pre_log_file = tempfile.NamedTemporaryFile()
    log_level = get_priority_setting("log_level", *settings_pack)
    if log_level is None:
        log_level = "debug"
    base_logger = logs.create_logger(filename=pre_log_file.name, level=log_level)
    global pre_logger
    pre_logger = logging.getLogger("SETTINGS")
    pre_logger.info("Loading runtime settings.")

    # Get runtime and science settings from file and CLI settings
    runtime_settings = get_runtime_settings(*settings_pack)
    science_settings = get_science_settings(*settings_pack)

    # Remove pre-program loggers
    base_logger.handlers.clear()
    pre_logger.handlers.clear()
    pre_log_file.close()

    # Create logging objects
    runtime_settings.setup_loggers()

    # Return runtime and science settings
    return runtime_settings, science_settings
