"""Configure and setup a program execution of the MorphFITS program.

There are two primary settings objects.
1. RuntimeSettings
    Settings related to runtime configurations, such as paths to data
    directories, which stages to run, which products to remake, etc.
2. ConfigSettings
    Settings related to scientific configurations, such as sigma generation
    algorithm.
"""

# Imports


import logging
import shutil
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Annotated, Union, Optional

from tqdm import tqdm
import yaml
from pydantic import BaseModel, StringConstraints

from . import DATA_ROOT
from .utils import logs, misc


# Constants


pre_logger = logging.getLogger("CONFIG")
logger = logging.getLogger("CONFIG")
"""Logger objects for this module.
"""


## Filesystem


PATH_STANDARDS_PATH = DATA_ROOT / "paths.yaml"
PATH_STANDARDS_DICT = yaml.safe_load(open(PATH_STANDARDS_PATH, mode="r"))
"""Path and dict representing the MorphFITS filesystem structuring standards.
"""


def index_paths(node: dict[str, str | dict], base: str) -> dict[str, str]:
    """Recursively read the MorphFITS filesystem standards YAML file and translate it into a
    dictionary mapping the path names to their corresponding paths, as string
    templates.

    Each value in the dictionary is a full path template, i.e. 'output_ficlo'
    has the value '[root]/[o]/{F}/{I}/{C}/{L}/{O}' and not '{O}'.

    Parameters
    ----------
    node : dict[str, str | dict]
        Dict mapping str path names to their paths (if a file) or subitems (if a
        directory).
    base : str
        Path prior to this node, as a '/'-delimited string.

    Returns
    -------
    dict[str, str]
        Dict mapping path names to their paths, as string templates.
    """
    # Start with an empty dict for this directory
    index = {}

    # Iterate over each subitem of this directory
    for key, value in node.items():
        # Skip meta keys as they are not subitems
        if key == "_name":
            continue

        # Add files to dictionary
        if isinstance(value, str):
            index[key] = base + "/" + value

        # Add subdirectories to dictionary
        else:
            index[key] = value["_name"]
            if len(base) > 0:
                index[key] = base + "/" + index[key]

            # Concatenate this directory's dictionary with the dictionary
            # generated by the subdirectory
            index = index | index_paths(node=value, base=index[key])

    # Return dictionary from path name to path for this directory
    return index


FILESYSTEM = index_paths(node=PATH_STANDARDS_DICT, base="")
"""Paths to directories and files, as structured and named by `PATH_STANDARDS`.
"""


DEFAULT_INPUT_DIRECTORY_NAME = "inputs"
DEFAULT_OUTPUT_DIRECTORY_NAME = "outputs"
DEFAULT_PRODUCT_DIRECTORY_NAME = "products"
DEFAULT_RUN_DIRECTORY_NAME = "runs"
"""Default names for each top-level root directory.
"""


## Required Files


REQUIRED_INPUT_DIRECTORIES = ["input_psfs", "input_fil"]
REQUIRED_OUTPUT_DIRECTORIES = ["output_ficlo", "product_ficlo"]
"""Path names of required directories for MorphFITS to run on a FICLO.
"""


REQUIRED_PRODUCT_FILES = ["stamp", "sigma", "psf", "mask"]
REQUIRED_GALFIT_OUTPUT_FILES = ["model_galfit"]
REQUIRED_IMCASCADE_OUTPUT_FILES = ["model_imcascade"]
REQUIRED_PYSERSIC_OUTPUT_FILES = ["model_pysersic"]
"""Path names of required files for a FICLO to be considered successful.
"""


# Classes


## Models


class FICL(BaseModel):
    """Configuration model for a single FICL.

    FICL is an abbreviation for the field, image version, catalog version, and
    filter of a JWST science observation. Each FICL corresponds to a single
    observation.

    Attributes
    ----------
    field : str
        Field of observation, e.g. "abell2744clu".
    image_version : str
        Version string of JWST image processing, e.g. "grizli-v7.2".
    catalog_version : str
        Version string of JWST cataloging, e.g. "dja-v7.2".
    filter : str
        Observational filter band, e.g. "f140w".
    objects : list[int]
        Integer IDs of galaxies or cluster targets in catalog.
    pixscale : tuple[float, float]
        Pixel scale along x and y axes, in arcseconds per pixel.

    Notes
    -----
    All strings are converted to lowercase upon validation.
    """

    field: Annotated[str, StringConstraints(to_lower=True)]
    image_version: Annotated[str, StringConstraints(to_lower=True)]
    catalog_version: Annotated[str, StringConstraints(to_lower=True)]
    filter: Annotated[str, StringConstraints(to_lower=True)]
    objects: list[int]
    pixscale: tuple[float, float]

    def __str__(self) -> str:
        return "_".join(
            [self.field, self.image_version, self.catalog_version, self.filter]
        )


## Settings


class StageSettings(BaseModel):
    unzip: bool = True
    product: bool = True
    morphology: bool = True
    catalog: bool = True
    histogram: bool = True
    plot: bool = True
    cleanup: bool = True


class ProductSettings(BaseModel):
    stamps: bool = False
    sigmas: bool = False
    psfs: bool = False
    masks: bool = False
    others: bool = False


class GALFITSettings(BaseModel):
    binary: Path


class ImcascadeSettings(BaseModel):
    pass


class PysersicSettings(BaseModel):
    pass


class PathSettings(BaseModel):
    root: Path
    input: Path
    output: Path
    product: Path
    run: Path


class RuntimeSettings(BaseModel):
    roots: PathSettings
    date_time: datetime
    run_number: int = 1
    process_count: int = 1
    process_id: int = 0
    ficls: list[FICL]
    progress_bar: bool = False
    log_level: int = logging.DEBUG
    stages: Optional[StageSettings] = None
    remake: Optional[ProductSettings] = None
    morphology: Optional[Union[GALFITSettings, ImcascadeSettings, PysersicSettings]] = (
        None
    )

    def setup_directories(self, initialized: bool = True):
        pre_logger.info("Making missing directories.")

        # Create run directory
        get_path(name="run", runtime_settings=self, field=self.ficls[0].field).mkdir(
            parents=True, exist_ok=True
        )

        # If running morphology, only create output and product directories
        if initialized:
            # Iterate over each FICL
            for ficl in self.ficls:
                # Iterate over each object in FICL
                for object in tqdm(ficl.objects, unit="dir", leave=False):
                    # Make leaf FICLO directories
                    for required_directory_name in REQUIRED_OUTPUT_DIRECTORIES:
                        get_path(
                            name=required_directory_name,
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        ).mkdir(parents=True, exist_ok=True)

        # If running initialize command, only create input directories
        else:
            # Iterate over each FICL
            for ficl in self.ficls:
                # Make PSF and FIL directories, and any parents
                for required_directory_name in REQUIRED_INPUT_DIRECTORIES:
                    get_path(
                        name=required_directory_name,
                        path_settings=self.roots,
                        ficl=ficl,
                    ).mkdir(parents=True, exist_ok=True)

    def cleanup_directories(self):
        logger.info("Removing skipped directories.")

        # Iterate over each FICL
        for ficl in self.ficls:
            # Iterate over each object in FICL
            for object in tqdm(ficl.objects, unit="dir", leave=False):
                # Iterate over each expected product file
                for required_file_name in REQUIRED_PRODUCT_FILES:
                    # Remove product directory for FICLO if any product missing
                    product_path = get_path(
                        name=required_file_name,
                        path_settings=self.roots,
                        ficl=ficl,
                        object=object,
                    )
                    if not product_path.exists():
                        product_ficlo_path = get_path(
                            name="product_ficlo",
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        )
                        shutil.rmtree(product_ficlo_path)

                # Iterate over each expected output file
                if isinstance(self.morphology, GALFITSettings):
                    required_output_files = REQUIRED_GALFIT_OUTPUT_FILES
                elif isinstance(self.morphology, ImcascadeSettings):
                    required_output_files = REQUIRED_IMCASCADE_OUTPUT_FILES
                else:
                    required_output_files = REQUIRED_PYSERSIC_OUTPUT_FILES
                for required_file_name in required_output_files:
                    # Remove output directory for FICLO if any product missing
                    product_path = get_path(
                        name=required_file_name,
                        path_settings=self.roots,
                        ficl=ficl,
                        object=object,
                    )
                    if not product_path.exists():
                        product_ficlo_path = get_path(
                            name="output_ficlo",
                            path_settings=self.roots,
                            ficl=ficl,
                            object=object,
                        )
                        shutil.rmtree(product_ficlo_path)

    def write(self):
        logger.info("Recording runtime settings.")

        # Initialize empty dict for writing
        settings = {}

        # Add paths as strings
        settings["roots"] = {}
        for root_name in self.roots.__dict__:
            settings["roots"][root_name] = str(self.roots.__dict__[root_name])

        # Add stages as a list of stages ran
        if self.stages is not None:
            settings["stages"] = []
            for stage in self.stages.__dict__:
                if self.stages.__dict__[stage]:
                    settings["stages"].append(stage)

        # Add remake flags as a list of products remade
        if self.remake is not None:
            settings["remake"] = []
            for product in self.remake.__dict__:
                if self.remake.__dict__[product]:
                    settings["remake"].append(product)

        # Add morphology wrapper as a str
        if self.morphology is not None:
            if isinstance(self.morphology, GALFITSettings):
                settings["morphology"] = "GALFIT"
            elif isinstance(self.morphology, ImcascadeSettings):
                settings["morphology"] = "imcascade"
            else:
                settings["morphology"] = "pysersic"

        # Add FICLs as a list of dicts
        settings["ficls"] = []
        for ficl in self.ficls:
            settings["ficls"].append(ficl.__dict__)

        # Add run details
        settings["date_time"] = misc.get_str_from_datetime(date_time=self.date_time)
        settings["run_number"] = misc.get_str_from_run_number(
            run_number=self.run_number
        )
        settings["process_count"] = self.process_count
        settings["process_id"] = self.process_id
        settings["progress_bar"] = self.progress_bar
        settings["log_level"] = self.log_level

        # Write settings to file
        settings_path = get_path(
            name="run_settings", runtime_settings=self, field=self.ficls[0].field
        )
        yaml.safe_dump(settings, open(settings_path, mode="w"))


class ScienceSettings(BaseModel):
    pass


# Functions


## Tertiary


def get_preferred_path(
    name: str, cli_settings: dict, file_settings: dict
) -> Path | None:
    # Try getting preferred setting and casting to path object
    try:
        path_str = get_priority_setting(name, cli_settings, file_settings)
        return misc.get_path_obj(path_str)

    # If setting unset or invalid, return None
    except:
        return


## Secondary


def get_priority_setting(
    name: str, cli_settings: dict, file_settings: dict
) -> bool | int | Path | None:
    # Return setting from CLI call if set
    if cli_settings[name] is not None:
        return cli_settings[name]

    # Return setting from YAML file if set
    elif name in file_settings:
        return file_settings[name]

    # Return None if unset


def get_path_settings(cli_settings: dict, file_settings: dict) -> PathSettings:
    # Set initialized flag from parameter from main command
    initialized = cli_settings["initialized"]

    # Get either path objects or None
    root = get_preferred_path("morphfits_root", cli_settings, file_settings)
    input = get_preferred_path("input_root", cli_settings, file_settings)
    output = get_preferred_path("output_root", cli_settings, file_settings)
    product = get_preferred_path("product_root", cli_settings, file_settings)
    run = get_preferred_path("run_root", cli_settings, file_settings)

    # Input root must be set
    if input is None:
        # Terminate if MorphFITS root is also unset
        if root is None:
            raise ValueError("Terminating - input root unset.")

        # Otherwise assume input root exists and is under root
        else:
            input = root / DEFAULT_INPUT_DIRECTORY_NAME
            assert input.exists(), f"Terminating - input root {input} not found."

    # Input root should exist
    elif not input.exists():
        # Terminate if input root set but does not exist
        if initialized:
            raise FileNotFoundError(f"Terminating - input root {input} not found.")

        # Create input root if main command is initialize
        else:
            input.mkdir(parents=True)

    # Set root directory, if not found, as parent of input root
    if root is None:
        root = input.parent

    # Set product, output, and run directories from root directory
    if output is None:
        output = root / DEFAULT_OUTPUT_DIRECTORY_NAME
    if product is None:
        product = root / DEFAULT_PRODUCT_DIRECTORY_NAME
    if run is None:
        run = root / DEFAULT_RUN_DIRECTORY_NAME

    # Return created and validated object
    return PathSettings(root=root, input=input, output=output, product=product, run=run)


def get_ficls(
    cli_settings: dict,
    file_settings: dict,
    process_count: int,
    process_id: int,
    first_object: int,
    last_object: int,
) -> list[FICL]:
    pass


def get_ficls_to_initialize(cli_settings: dict, file_settings: dict) -> list[FICL]:
    # Get preferred FIL settings
    # NOTE Terminates if any of FIL unset, in future can implement discovery
    fields = get_priority_setting("fields", cli_settings, file_settings)
    imvers = get_priority_setting("image_versions", cli_settings, file_settings)
    filters = get_priority_setting("filters", cli_settings, file_settings)

    # Iterate over each FIL permutation
    # NOTE Uses default catalog version
    ficls = []
    for field in fields:
        for imver in imvers:
            for filter in filters:
                # Create FICL object and add to list
                ficl = FICL(field=field, image_version=imver)


def get_run_number(path_settings: PathSettings, field: str, date_time: datetime) -> int:
    # Set run number to 1 by default
    run_number = 1

    # If any other processes in same batch use same date time, increase the run
    # number until there is a free directory
    while get_path(
        "run",
        run_root=path_settings.run,
        field=field,
        datetime=date_time,
        run_number=run_number,
    ).exists():
        run_number += 1

    # Return run number
    return run_number


## Primary


def get_path(
    name: str,
    runtime_settings: RuntimeSettings | None = None,
    path_settings: PathSettings | None = None,
    ficl: FICL | None = None,
    morphfits_root: Path | None = None,
    input_root: Path | None = None,
    output_root: Path | None = None,
    product_root: Path | None = None,
    run_root: Path | None = None,
    field: str | None = None,
    image_version: str | None = None,
    catalog_version: str | None = None,
    filter: str | None = None,
    object: int | None = None,
    date_time: datetime | None = None,
    run_number: int | None = None,
) -> Path:
    """Get the path to a MorphFITS file or directory.

    Parameters
    ----------
    name : str
        Name of path to get.
    runtime_settings : RuntimeSettings | None, optional
        Settings for the runtime of MorphFITS, by default None.
    path_settings : PathSettings | None, optional
        Paths to the root directories of MorphFITS, by default None.
    ficl : FICL | None, optional
        FICL object for current iteration in run, by default None.
    morphfits_root : Path | None, optional
        Path to root of MorphFITS filesystem, by default None.
    input_root : Path | None, optional
        Path to root input directory, by default None.
    output_root : Path | None, optional
        Path to root output directory, by default None.
    product_root : Path | None, optional
        Path to root products directory, by default None.
    run_root : Path | None, optional
        Path to root runs directory, by default None.
    field : str | None, optional
        Field of observation, by default None.
    image_version : str | None, optional
        Image version of science frame, by default None.
    catalog_version : str | None, optional
        Catalog version of science frame, by default None.
    filter : str | None, optional
        Filter used in observation, by default None.
    object : int | None, optional
        Target galaxy or cluster ID in catalog, by default None.
    date_time : datetime | None, optional
        Datetime at start of program run, by default None.
    run_number : int | None, optional
        Number of run in collection with same datetime, by default None.

    Returns
    -------
    Path
        Path to file or directory.

    Raises
    ------
    FileNotFoundError
        Passed path name unrecognized.

    See Also
    --------
    data/paths.yaml
        Data standards dictionary detailing MorphFITS paths.
    """
    # Raise error if path name unknown
    if name not in FILESYSTEM:
        raise FileNotFoundError(f"Unknown MorphFITS path name {name}.")

    # Resolve parameters
    # Prefer directly passed parameters to those from settings objects
    if ficl is not None:
        if field is None:
            field = ficl.field
        if image_version is None:
            image_version = ficl.image_version
        if catalog_version is None:
            catalog_version = ficl.catalog_version
        if filter is None:
            filter = ficl.filter
    if runtime_settings is not None:
        if morphfits_root is None:
            morphfits_root = runtime_settings.roots.root
        if input_root is None:
            input_root = runtime_settings.roots.input
        if output_root is None:
            output_root = runtime_settings.roots.output
        if product_root is None:
            product_root = runtime_settings.roots.product
        if run_root is None:
            run_root = runtime_settings.roots.run
        if date_time is None:
            date_time = runtime_settings.date_time
        if run_number is None:
            run_number = runtime_settings.run_number
    if path_settings is not None:
        if morphfits_root is None:
            morphfits_root = path_settings.root
        if input_root is None:
            input_root = path_settings.input
        if output_root is None:
            output_root = path_settings.output
        if product_root is None:
            product_root = path_settings.product
        if run_root is None:
            run_root = path_settings.run

    # Input PSFs - STSci names with uppercase filter names
    if name == "input_psf":
        # Get main filter from pairs like 'f140w-clear'
        if "-" in filter:
            filter_1, filter_2 = filter.split("-")
            filter = filter_1 if "clear" in filter_2 else filter_2

        # Replace filter template with uppercase main filter name
        path.replace("{L}", filter.upper())

    # Replace template in path str with passed value
    path = FILESYSTEM[name]
    path.replace("[root]", str(morphfits_root))
    path.replace("[i]", input_root.name)
    path.replace("[o]", output_root.name)
    path.replace("[p]", product_root.name)
    path.replace("[r]", run_root.name)
    path.replace("{F}", field)
    path.replace("{I}", image_version)
    path.replace("{C}", catalog_version)
    path.replace("{L}", filter)
    path.replace("{O}", object)
    path.replace("{D}", misc.get_str_from_datetime(date_time=date_time))
    path.replace("{N}", misc.get_str_from_run_number(run_number=run_number))

    # Science, exposure, weights images - can contain either 'drc' or 'drz'
    if "{z}" in path:
        # Get paths to both 'drc' and 'drz'
        path_c = misc.get_path_obj(path_like=path.replace("{z}", "c"))
        path_z = misc.get_path_obj(path_like=path.replace("{z}", "z"))

        # Return option that exists
        if path_c.exists():
            return path_c
        elif path_z.exists():
            return path_z
        else:
            raise FileNotFoundError(
                f"Input file '{name}' found with neither 'drc' nor 'drz'."
            )

    # Return resolved path object
    return misc.get_path_obj(path_like=path)


def get_runtime_settings(cli_settings: dict, file_settings: dict) -> RuntimeSettings:
    # Set initialized flag from parameter passed from main command
    initialized = cli_settings["initialized"]

    # Set root paths
    roots = get_path_settings(cli_settings, file_settings)

    # Set primitive runtime setting attributes
    date_time = misc.get_str_from_datetime(datetime.now())
    progress_bar = get_priority_setting("progress_bar", cli_settings, file_settings)
    log_level = get_priority_setting("log_level", cli_settings, file_settings)
    process_count = get_priority_setting("batch_n_process", cli_settings, file_settings)
    process_id = get_priority_setting("batch_process_id", cli_settings, file_settings)
    first_object = get_priority_setting("first_object", cli_settings, file_settings)
    last_object = get_priority_setting("last_object", cli_settings, file_settings)

    #
    ficls = get_ficls(
        cli_settings=cli_settings,
        file_settings=file_settings,
        process_count=process_count,
        process_id=process_id,
        first_object=first_object,
        last_object=last_object,
    )

    #
    run_number = get_run_number(
        path_settings=roots, field=ficls[0].field, date_time=date_time
    )

    #
    stages = get_stage_settings(cli_settings, file_settings)

    #
    remake = get_product_settings(cli_settings, file_settings)

    #
    morphology = get_morphology_settings(cli_settings, file_settings)

    # Create object dict from settings that have been set
    ## Set attributes which have definitely been set by this point
    runtime_dict = {"roots": roots, "date_time": date_time, "ficls": ficls}

    ## Set attributes which may be None at this point, if they are set
    ## Otherwise they will be set to default as per the class definition
    if run_number is not None:
        runtime_dict["run_number"] = run_number
    if process_count is not None:
        runtime_dict["process_count"] = process_count
    if process_id is not None:
        runtime_dict["process_id"] = process_id
    if progress_bar is not None:
        runtime_dict["progress_bar"] = progress_bar
    if log_level is not None:
        runtime_dict["log_level"] = log_level
    if stages is not None:
        runtime_dict["stages"] = stages
    if remake is not None:
        runtime_dict["remake"] = remake
    if morphology is not None:
        runtime_dict["morphology"] = morphology

    # Create class instance from settings
    runtime_settings = RuntimeSettings(**runtime_dict)

    #
    runtime_settings.setup_directories(initialized=initialized)

    #
    runtime_settings.setup_loggers()

    #
    return runtime_settings


def get_science_settings() -> ScienceSettings:
    pass


def get_settings(
    config_path: Path | None = None,
    morphfits_root: Path | None = None,
    input_root: Path | None = None,
    output_root: Path | None = None,
    product_root: Path | None = None,
    run_root: Path | None = None,
    batch_n_process: int | None = None,
    batch_process_id: int | None = None,
    fields: list[str] | None = None,
    image_versions: list[str] | None = None,
    catalog_versions: list[str] | None = None,
    filters: list[str] | None = None,
    objects: list[int] | None = None,
    first_object: int | None = None,
    last_object: int | None = None,
    progress_bar: bool | None = None,
    log_level: int | None = None,
    skip_unzip: bool | None = None,
    skip_product: bool | None = None,
    skip_morphology: bool | None = None,
    skip_catalog: bool | None = None,
    skip_histogram: bool | None = None,
    skip_plot: bool | None = None,
    skip_cleanup: bool | None = None,
    remake_all: bool | None = None,
    remake_stamps: bool | None = None,
    remake_sigmas: bool | None = None,
    remake_psfs: bool | None = None,
    remake_masks: bool | None = None,
    remake_others: bool | None = None,
    morphology: str | None = None,
    galfit_path: Path | None = None,
    initialized: bool | None = None,
) -> tuple[RuntimeSettings, ScienceSettings]:
    # Create a temporary logger
    pre_log = tempfile.NamedTemporaryFile()
    base_logger = logs.create_logger(filename=pre_log.name)
    pre_logger = logging.getLogger("CONFIG")
    pre_logger.info("Loading runtime settings.")

    # Get CLI settings as dict from passed parameters
    cli_settings = locals()

    # Get file settings as dict from YAML file
    if config_path is None:
        file_settings = {}
    else:
        pre_logger.info(f"Loading runtime settings from {config_path}.")
        file_settings = yaml.safe_load(open(config_path, mode="r"))

    # Get runtime and science settings from file and CLI settings
    runtime_settings = get_runtime_settings(cli_settings, file_settings)
    science_settings = get_science_settings(cli_settings, file_settings)

    # Remove pre-program loggers
    base_logger.handlers.clear()
    pre_logger.handlers.clear()
    pre_log.close()

    # Return runtime and science settings
    return runtime_settings, science_settings
